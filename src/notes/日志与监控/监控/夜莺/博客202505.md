## 背景
公司有多个云平台/云环境，每个环境有一个 Kubernetes 集群，有的环境还有独立于集群外的若干服务器，之前的监控架构是每个云环境的 Kuberntes 集群中部署一套监控系统，每套系统包括 Prometheus Server + alertmanager + alertmanager-webhook-dingtalk + prometheus-node-exporter + （集群外 node-exporter） ，然后将告警信息使用钉钉来推送。

## 问题
当只有几个集群的时候，还能手动管理下，主要是使用 yaml 维护具体的告警规则、告警通道等，当集群多的时候就比较麻烦，可能一个告警规则要配置到多个集群中，存在重复手工操作的问题，而且手动维护 yaml 也很麻烦。因为这么多环境也有甲方的也有我们自己的，所以我们期望在不大改目前架构的基础上找一个工具来集中管理下告警规则、告警通道等

## 解决
Pormetheus server 作为数据源接入夜莺，使用夜莺来管理、复用告警规则，管理告警通道、管理维护人员等

### 架构

老架构

![image-20250512181538028](%E5%8D%9A%E5%AE%A2202505.assets/image-20250512181538028.png)

新架构

![image-20250512181556729](%E5%8D%9A%E5%AE%A2202505.assets/image-20250512181556729.png)



### 部署

刚开始使用helm 部署的 v5 版本，后来升级到了 v6,目前是升级到了v7，参考官方文档，发现helm 支持的不够好，目前是用 yaml 直接部署在 k8s 集群里的，具体 yaml 如下：

```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  labels:
    app: n9e
  name: n9e-nightingale-center
  namespace: monitor
spec:
  ingressClassName: kong
  rules:
  - host: x
    http:
      paths:
      - backend:
          service:
            name: n9e-nightingale-center
            port:
              number: 80
        path: /
        pathType: Prefix
  tls:
  - hosts:
    - x
    secretName: n9e-tls
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: n9e
  name: n9e-nightingale-center
  namespace: monitor
spec:
  clusterIP:
  internalTrafficPolicy: Cluster
  ipFamilies:
  - IPv4
  ipFamilyPolicy: SingleStack
  ports:
  - name: port
    port: 80
    protocol: TCP
    targetPort: 17000
  selector:
    app: n9e
  sessionAffinity: None
  type: ClusterIP
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: n9e-config
  namespace: monitor
  labels:
    app: n9e
data:
  config.toml: |-
    [global]
    RunMode = "release"

    [Log]
    Dir = "logs"
    Level = "INFO"
    Output = "stdout"

    [HTTP]
    Host = "0.0.0.0"
    Port = 17000
    CertFile = ""
    KeyFile = ""
    PrintAccessLog = false
    PProf = false
    ExposeMetrics = true
    ShutdownTimeout = 30
    MaxContentLength = 67108864
    ReadTimeout = 20
    WriteTimeout = 40
    IdleTimeout = 120

    [HTTP.ShowCaptcha]
    Enable = false

    [HTTP.APIForAgent]
    Enable = true

    [HTTP.APIForService]
    Enable = false
    [HTTP.APIForService.BasicAuth]
    user001 = "x"

    [HTTP.JWTAuth]
    AccessExpired = 1500
    RefreshExpired = 10080
    RedisKeyPrefix = "/jwt/"

    [HTTP.ProxyAuth]
    Enable = false
    HeaderUserNameKey = "X-User-Name"
    DefaultRoles = ["Standard"]

    [HTTP.RSA]
    OpenRSA = false

    [DB]
    DSN="x:x@tcp(x:3306)/n9e?charset=utf8mb4&parseTime=True&loc=Local&allowNativePasswords=true"
    Debug = false
    DBType = "mysql"
    MaxLifetime = 7200
    MaxOpenConns = 150
    MaxIdleConns = 50

    [Redis]
    Address = "x:6379"
    Password = "x"
    RedisType = "standalone"

    [Alert]
    [Alert.Heartbeat]
    IP = ""
    Interval = 1000
    EngineName = "default"

    [Center]
    MetricsYamlFile = "/app/etc/metrics.yaml"
    I18NHeaderKey = "X-Language"

    [Center.AnonymousAccess]
    PromQuerier = true
    AlertDetail = true

    [Pushgw]
    LabelRewrite = true
    ForceUseServerTS = true

    [[Pushgw.Writers]]
    Url = "http://prometheus-server.monitor:80/api/v1/write"
    BasicAuthUser = ""
    BasicAuthPass = ""
    Headers = ["X-From", "n9e"]
    Timeout = 10000
    DialTimeout = 3000
    TLSHandshakeTimeout = 30000
    ExpectContinueTimeout = 1000
    IdleConnTimeout = 90000
    KeepAlive = 30000
    MaxConnsPerHost = 0
    MaxIdleConns = 100
    MaxIdleConnsPerHost = 100

    [Ibex]
    Enable = false
    RPCListen = "0.0.0.0:20090"
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: n9e-nightingale-center
  namespace: monitor
  labels:
    app: n9e
spec:
  replicas: 1
  selector:
    matchLabels:
      app: n9e
  template:
    metadata:
      labels:
        app: n9e
    spec:
      containers:
      - args:
          - /app/n9e
          - configs
          - /app/etc
        env:
          - name: GIN_MODE
            value: release
          - name: TZ
            value: Asia/Shanghai
        image: flashcatcloud/nightingale:7.7.2
        name: center
        ports:
          - containerPort: 17000
        resources: {}
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
        volumeMounts:
        - mountPath: /app/etc/config.toml
          name: n9e-config
          subPath: config.toml
      dnsPolicy: ClusterFirst
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext: {}
      terminationGracePeriodSeconds: 30
      volumes:
      - name: n9e-config
        configMap:
          name: n9e-config
          items:
          - key: config.toml
            path: config.toml
```



### 配置

数据源配置

集成中心 --> 数据源 --> 新增 --> Prometheus Like --> 填入信息  --> 测试保存

![image-20250513111543943](%E5%8D%9A%E5%AE%A2202505.assets/image-20250513111543943.png)





人员管理

人员组织 --> 用户管理 --> 新增 ，联系方式选择 dingtalk_robot_token (此处要先在钉钉群新建机器人然后复制 webhook 连接的 token；这个用户就是钉钉机器人告警的通道

![image-20250513134752034](%E5%8D%9A%E5%AE%A2202505.assets/image-20250513134752034.png)

团队管理

根据业务项目或者钉钉群来创建团队，团队包括上面创建的人员，告警规则将告警通知的对象也就是团队

人员组织 --> 团队管理 --> 新增，然后将人员加入到团队里

![image-20250513134714601](%E5%8D%9A%E5%AE%A2202505.assets/image-20250513134714601.png)

业务组管理

夜莺里有个业务组的概念，你可以理解为告警规则组，官方解释是“告警规则，告警事件，监控对象，自愈脚本等都归属业务组，是一个在系统里可以自闭环的组织”。

人员组织 --> 业务组管理 --> 新增，然后添加上面创建的团队

![image-20250513134959253](%E5%8D%9A%E5%AE%A2202505.assets/image-20250513134959253.png)

告警规则管理

告警管理 --> 告警规则 --> 选择业务组 --> 新增，然后命名规则名称，选择数据源，告警条件，执行频率持续时间，通知媒介，告警接受组，重复通知时间等信息



![image-20250513135224977](%E5%8D%9A%E5%AE%A2202505.assets/image-20250513135224977.png)

![image-20250513135429714](%E5%8D%9A%E5%AE%A2202505.assets/image-20250513135429714.png)

### 使用

即时查询

时序指标 -->即时查询，相当于 prometheus 查询面板所以不过多赘述了

活跃告警

告警管理 --> 活跃告警，就是目前的告警情况，可以当作告警面板用

![image-20250513135550056](%E5%8D%9A%E5%AE%A2202505.assets/image-20250513135550056.png)





## 写在最后

这个架构虽然不是最优解，但是这是基于老的架构、公司的业务需求来整合的一套架构，目前使用起来还可以，但是也发现了一些问题，正好也请教下大家：夜莺每隔 30s 去请求 prometheus server 数据源从而来匹配告警规则是否触发，总是有404的error，不太清楚是什么问题，在数据源那里设置的是10000ms ,应该不会是网络超时，具体报错如下

```
2025-05-13 14:04:50.993389 ERROR eval/eval.go:235 rule_eval:alert-12-739 promql:round((1 - node_filesystem_files_free / node_filesystem_files) * 100) > 85, error:client_error: client error: 404
2025-05-13 14:04:50.993430 ERROR eval/eval.go:142 rule_eval:alert-12-739 get anomaly point err:client_error: client error: 404

```

